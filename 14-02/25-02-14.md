## Split Query Processing in Polybase

Polybase is a feature of SQL Server which allows management and interaction with HDFS stored data in a Hadoop cluster using SQL.
Using the split query processing paradigm, SQL query plans are translated into Map-Reduce jobs that can run over the Hadoop cluster.
 - Using this technique, structured and unstructured data can be simultaneously queried.
 - Moreover, query optimizing specific to the split-query processing paradigm are presented.
 
Exisiting Work :
 - Sqoop (SQL-to-Hadoop) : external tables over HDFS files on which SQL queries can be used (the tables being updated using an incremental view maintenance mechanism).
 - Hadapt : system which integrates relational and Hadoop components into a single system.

Hadapt vs Polybase:
 - Hadapt adds a relational database to each node in the Hadoop cluster and uses MapReduce to do parellel processing between the nodes.
 - Polybase uses a parallel RDBMS (including query optimizer and query engine) and uses MapReduce as an auxiliary engine to process HDFS specific data.

### Hadapt Algorithms :
 - selections :
   - For data located on the HDFS, the selection predicate is translated into a Map-Reduce job and distributed across the Hadoop Cluster.
   - For data in the relational database of one of the nodes in the cluster, the selection will be executed by the query engine of the database installed on that node.
 - Given inputs relations R (from the HDFS) and S (from the RDBMS), two alternative exists to process R \join S: 
   - Partition R across nodes on the join attribute and export each partition into the node's RDBMS. Partition S as well and write matching partitions to the RDBMS over other nodes.
   - Partition S and export each partition to HDFS, then use MapReduce to perform the join.

### Polybase architecture :
Polybase is used on top of SQL Server PDW. Overview of SQL Server PDW architecture :
 - control nodes :
   - parse SQL
   - Validate the query and build initial query plan.
   - Optimize distributed query plan
   - Send subplans to compute nodes
   - return data to client
 - compute nodes :
   - hold the data
   - compute the parallel processing and return results to control nodes.
  
Polybase Use Cases :
 - Data required from Hadoop in PDW. Send a MR job to Hadoop and recieve the HDFS blocks for query processing on PDW.
 - Data from PDW required in Hadoop. Send result of PDW query into a HDFS file, and send a MR job to tell Hadoop what to do with it.

### Communication between PDW and HDFS
 - HDFS is integrated into polybase as an external table.
 - Data transfer is coordinated by a HDFS bridge. 




#### Concepts :
External Table : 
 - External Table are a way to access data in external sources as an SQL table. In current commercial RDBMS, these must be represented by files 
 which meet a current format (Oracle requires '.dat' files with data in rows seperated by spaces).

Fault Tolerant Data Storage Cluster:
 - Ability to preserve state and consistency and availability despite the failure of one or more (but not all) nodes in the cluster.   
  
SQL Server Data Movement Service :
 - service which allows data interactions between PDW compute and control nodes, as well as interaction with HDFS.

Hadoop Name Node :
The hadoop name node is the centerpiece of the Hadoop cluster and HDFS. It contains the directory tree of all files in the filesystem, and tracks where data for each file is kept across the cluster. It doesn't store the data itself.  