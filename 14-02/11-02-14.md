## Papers
We are reading three additional papers, in the idea of having more to show for the sql survey.

### I/O Characteristics of NoSQL Databases
 - NoSQL database have brought a new model of storage systems.
 - The weaker data consistency models means NoSQL DBMS need 

### Can the Elephants handle the NoSQL Onslaught
 - This paper investigates whether the advent of NoSQL databases can render traditional irrelevant, in particular in the context of web applications and big data analytics.
 - 

### Solving Big Data Challenges for Entreprise Application Performance Management
 - This article surveys the performance of different NoSQL platforms in the setting of a Application Performance Monitoring (APM) application.
 - NoSQL databases are more suited than relational DBMS for APMs.
   - APMs require storing huge amounts of data.
   - APMs require keeping an up-to-date view of data despite very high update rates.
   - APMs do not require strong consistency.
 - The following NoSQL systems are compared :
   - Apache Cassandra : Distributed key-value store (developped by Facebook). Handles large amounts of data spread across many commodity servers. Read and Write throughput increase linearly. No single point of failure.
   - Apache HBase : open-source, distributed, column oriented database system written in Java, running on top of Apache Hadoop and Apache Zookeeper and using the Apache Distributed File System(DFS). 
   - Project Voldemort : Distributed key-value store (developped by LinkedIn). Offers a distributed, fault tolerant, persisten hash table. Everynode is responsible for a subset ofdata, independent from other nodes. No central coordination required. Project Voldemort does not have persistence by default, but can be easily implemented through a simple API. 
   - Redis : in-memory key-value data store. Data can be persisted by taking a snapshot of the data and dumping it on disk periodically. Master uses the master-slave architecture for data replication. In particular, Redis a master-slave hierarchy (a slave node can be master node to other nodes). 
   - VoltDB : ACID compliant in memory data base. Each node is the unique owner and responsible for a subset of partitions.
   - MySQL cluster : shared nothing distributed system, data is not shared across nodes. It is not a NoSQL database, but a single table with key-value pairs was used. 
 - Performance Evaluation Setup
   - YCSB Benchmark
   - Records have a 25 bytes length key and 5 10 bytes values.
   - Workloads include [Read(R), ReadWrite(RW), Write(W), ReadScan(RS), ReadScanWrite(RSW)]. Scans are for the systems which support scans.
     - R : Read intensive workload.
     - RS : Read intensive workload with 50% scans.
     - RW, RSW : Equal ratio of reads and writes.
   - Two types of clusters : Memory-Only (M) and Disk-Only (D)
   - Data set size : (M) 700MB per node, (D) 10.5GB per node
 - Experimental Results
   - Cassandra has the best maximum throughput across all workloads, performing on average ten times better than HBase (which has the lowest throughput).
   - Redis and Project Voldemort consistently have the best (lowest) read latency, while HBase has the highest (100 times higher than Redis).
   - HBase has consistently the lowest write latency.
   - Cassandra has the lowest read latency on bounded throughput (more common, real world case).
   - Cassandra has the lowest disk usage while HBase has the highest (8 times that of Cassandra).
   - Redis displays an unbalanced distribution of data.
   - Previous results were giving for the (M) cluster. However, results are similar for the (D) cluster.
   
### Distributed System Architecture 

#### Distributed HashTable
 - Class of centralized distributed systems
 - Data is distributed over a giant hash table distributed over all the peers (each peer has a part of the hash table).
 - Responsibility for maintaining the key mapping is also distributed among peers in such a way that minimizes disruption (if one node fails, the keys it mapped should also be mapped elsewhere).

#### Shared Nothing Architecture 
 - Each node is independent and self sufficient.
 - Data is not (or very little) shared across nodes.
 - consistency and data access is maintained through protocols.
 - No point of contention 
 - sharding : partition data among many databases on different machines. 